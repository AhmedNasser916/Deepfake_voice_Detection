
# Audio Gardien

The potential use of deep fakes for identity theft, disinformation, and manipulation gives rise to the urgent need for efficient detection systems. We intend to build a robust system capable of differentiating between genuine and manipulated audio signals by utilizing various machine learning techniques and cutting-edge Deep Learning technique. The project is significant for our sponsors, end users, and a broader audience since it addresses the rising concern about audio deep fakes. 
## Dependencies

The following frameworks, libraries, and design tools are used in this project:

- [pandas](https://pandas.pydata.org/)
- [streamlit](https://www.streamlit.io/)
- [keras](https://keras.io/)
- [numpy](https://numpy.org/)
- [librosa](https://librosa.org/)
- [matplotlib](https://matplotlib.org/)
- [Figma](https://www.figma.com/)

## Roadmap

![project workflow](https://github.com/esraa-mahmoudsaid/Classification-of-Mental-Disorders-in-Egyptian-dialect-of-Arabic/assets/132246508/5d37b9fa-1c4c-41db-9b43-c47cf5185b98)
## Demo

[demo](https://youtu.be/QE328cv7M2U)


## Documentation

[Documentation](https://drive.google.com/file/d/1TCSFwsKAxfuxPYYISkpkGFR9E55MRO0B/view?usp=sharing)

## Note 
all data on folder 'data set waves' are samlpes from our dataset 

Ensure that all CSV files are located in the folder named 'get the best number of k feature of MFCC,' including the dataset. 
As a result of the 2 GB upload limit for our project, we have provided the data in CSV format instead of WAV files, 
which would have amounted to 28 GB. Please note that the CSV files are only intended for the folder 'final model training' 

You can access our dataset through the following link: [Dataset Link](https://zenodo.org/records/5642694). 
After downloading the dataset, replace the contents inside the 'data set waves' folder 


## Installation

Follow these steps to get our project up and running:

1. **Clone the Repository:**
```bash
   git clone https://github.com/your-username/your-project.git
   cd your-project

2. **Install Requirements:**
```bash
pip install -r requirements.txt

```
3. **Run the Application:**
go to file deploymant and run this commend on bash or cmd
```bash
streamlit run main.py

```
make sure you are in the project path

## Acknowledgements

- Special thanks to our sponser Wakeb Tech Company represented by [Eng. Said Hamdi](s.hamdi@wakeb.tech) who had provided strategic insights in real-world applications.
- Egypt Mentor [Dr. Laila Afify](Laila.afify@kaust.edu.sa)  who had helped us navigate technical challenges and refine our approach.
- uOttawa Supporter [Dr. Murat](murat.simsek@uOttawa.ca) whose experience in ML and DL had a remarkable role in guiding us in modeling phase.

## Traning


1. Navigate to the 'get the best number of k feature of MFCC' folder.
2. Run the 'get features.ipynb' file.
3. Inside every sub-folder, run the two notebooks.
4. After obtaining the results, exit the current folder.
5. Go to the 'Final models training' folder.
6. Run the notebook named 'Final models training.ipynb.'
7. After completion, three models will be generated.
8. Copy these models from the 'deployment' folder.
9. Replace the existing models in the 'models' folder with the copied ones.

This sequence of steps should be followed to ensure proper execution and model deployment.


## Used By

This project is used by [Wakeb Company](https://wakeb.tech/)


## Authors

- [@Ahmed Nasser](https://github.com/AhmedNasser916)
- [@Ahmed Essam](https://github.com/AhmedEssam29)
- [@Esraa Mahmoudsaid](https://github.com/esraa-mahmoudsaid)
- [@Alaa Rabie](https://github.com/alaa1124)
- [@Omnia Elghazoly](https://github.com/Omniaelghazoly)


