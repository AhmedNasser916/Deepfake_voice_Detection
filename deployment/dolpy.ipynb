{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aa\\anaconda3\\envs\\ML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\aa\\anaconda3\\envs\\ML\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n",
      "c:\\Users\\aa\\anaconda3\\envs\\ML\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty list to store the data\n",
    "\n",
    "def getcsv(root_folder):\n",
    "    data = []\n",
    "    # Loop through the 'real' and 'fake' subfolders\n",
    "    # for label in ['real', 'fake']:\n",
    "    #     label_folder = os.path.join(root_folder, label)\n",
    "\n",
    "    #     # Check if the folder exists\n",
    "    #     if not os.path.exists(label_folder):\n",
    "    #         continue\n",
    "\n",
    "    #     # Loop through the audio files in each subfolder\n",
    "\n",
    "    def features_extractor(file):\n",
    "        audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "        mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=100)\n",
    "        mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "        return mfccs_scaled_features\n",
    "\n",
    "    def iterate_folder_and_extract_features(folder_path):\n",
    "        extracted_features = []\n",
    "        for file_name in tqdm(os.listdir(folder_path)):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if file_path.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n",
    "                data = features_extractor(file_path)\n",
    "                extracted_features.append([data])\n",
    "\n",
    "\n",
    "       \n",
    "        return extracted_features\n",
    "\n",
    "\n",
    "    # Assuming 'df' has an 'mfcc' column with MFCC lists\n",
    "\n",
    "\n",
    "    data = pd.DataFrame(iterate_folder_and_extract_features(root_folder), columns=[\"mfcc_features\"])\n",
    "    \n",
    "\n",
    "\n",
    "    df_expanded = pd.DataFrame(data[\"mfcc_features\"].tolist())\n",
    "\n",
    "    # # Combine the expanded MFCC columns with the original DataFrame\n",
    "    # df_expanded = pd.concat([data[['label']], df_expanded], axis=1)\n",
    "\n",
    "    # # The 'df_expanded' DataFrame now has each MFCC value in its own column\n",
    "\n",
    "    # df_expanded.to_csv(f\"df_{N_FFT}f\",index=False)\n",
    "\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=getcsv(\"C:\\\\Users\\\\aa\\\\Downloads\\\\VoxCeleb_gender\\\\New folder\")\n",
    "\n",
    "#df=getcsv(\"C:\\\\Users\\\\aa\\\\Downloads\\\\Elevenlabs_SAMPLE_DAVE_DOMI\\\\Domi\")\n",
    "\n",
    "\n",
    "#df = getcsv(\"C:\\\\Users\\\\aa\\\\Downloads\\\\badawy\")\n",
    "\n",
    "#df=getcsv(\"C:\\\\Users\\\\aa\\\\Downloads\\\\archive (2)\\\\Raw JL corpus (unchecked and unannotated)\\\\JL(wav+txt)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df = getcsv(\"C:\\\\Users\\\\aa\\\\Desktop\\\\New folder\")\n",
    "\n",
    "\n",
    "df = getcsv(\"C:\\\\Users\\\\aa\\\\Downloads\\\\Raw JL corpus (unchecked and unannotated)\\\\Perception test material on Qualtrics\\\\main_emotion\\\\main_survey_1\\\\page3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.array(df)\n",
    "\n",
    "df_s=df.reshape(df.shape[0], df.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=model.predict(df_s).argmax(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
